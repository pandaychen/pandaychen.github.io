---
layout:     post
title:      AI 关键点摘要
subtitle:   
date:       2025-12-24
author:     pandaychen
catalog:    true
tags:
    - AI
---

##  0x00    前言

##  0x01    AI 基础（白话）

1、LLM (大语言模型) ：超级大脑

所有 AI 的底座，可以把它想象成一个读过人类历史上所有书籍、见过所有代码、博古通今的超级学霸。它能理解你的意图，也能跟你聊天，但它本质上只是一个大脑，暂时还没手没脚

2、Agent （智能体） ：全能数字员工

如果 LLM 只是个大脑，那么 Agent 就是一个有了身体、目标、会思考的员工。

区别：问 LLM 问题，它回复你答案；给 Agent 一个任务（比如：帮我策划一场旅行并订好机票），它会自己拆解步骤、查资料、做决策，直到把事办完

3、RAG （检索增强生成） ：开卷考试

LLM 虽然博学，但它的知识有截止日期（比如不知道昨天的新闻）。RAG 就像是给这位学霸发了一本实时更新的参考书。当用户提问问题时，系统先去自己的私人数据库里翻一翻相关的资料（检索），再把资料喂给 LLM（增强），让它看着资料回答（生成）

4、Skills & Tools：手里的家伙事儿

-   Tools （工具） ： 这是 AI 能调用的外部功能。比如计算器、天气预报接口、Google 搜索等等，这让 AI 从只会动嘴变成了能干实事
-   Skills（技能）： 通常指 Agent 被赋予的一套组合动作。比如写周报是一个技能，它包含了读取日志、润色文字、发送邮件这一整套逻辑

5、MCP （模型上下文协议） ：统一的电源插头

MCP 就像是 USB-C 接口。只要大家都遵守这个标准，AI 就能无缝地插进各种数据库和软件里，直接读取数据，不用到处适配

6、Rules （规则/指令） ：员工手册

这是你给 AI 下的硬性规定。比如：回答必须简洁、不准说脏话、代码必须用 Python 写等等。它是用来约束 AI 行为的边界，防止它放飞自我

7、Vibe-coding & Spec-coding ：编程新姿势

-   Vibe-coding （氛围感编程）： 核心在于感觉。开发者不再写一行行的具体代码，而是通过和 AI 聊天，描述想要的效果（Vibe），让 AI 像魔法一样把功能变出来。主打一个顺手、直觉、高效
-   Spec-coding （规格驱动编程）： 核心在于严谨。你先写一份非常详细的说明书（Spec），规定好每一个功能细节。AI 就像一个完美的搬砖工，严格按照你的蓝图去施工，出错率极低

##  0x02 大模型（LLM）
LLM 是一个**读过海量资料、会接话、会写代码的超级助理大脑**，通俗解释可以把大模型想成一个：

-   读完了互联网上大量文字、代码、文档
-   学会了**下一句话应该怎么接**的超强概率机器

它本身不懂对错、不理解业务，只是在做一件事，即**在当前上下文下，最有可能出现的下一个词是什么**。由于它读过的东西实在太多，所以它的技能主要还是：

-   会写代码
-   会设计方案
-   会解释概念

不过，LLM不等于工具， 也不会自动干活（只能被动），它只是一个大脑，要干活还得配手（工具）和规则

##  0x03 Tools
Tools 是让 AI 干一件具体小事的具体工具，其特点是

-   单一功能
-   输入 -> 输出
-   不关心前后流程（给输入执行，并输出）

常用的实现有：

-   读取文件
-   写文件
-   执行命令
-   调用接口
-   查询数据库

##  0x04 Skills
Skills 就是让大模型真的能干活的具体能力按钮（工具），通俗解释，如果把 LLM 看作一个聪明人：

-   LLM：脑子很聪明
-   Skills：给LLM配的工具和技能

比如在 Cursor/Claude CLI 里使用到的功能：能直接改项目/知道上下文/能跑测试等等，本质都是 Skills 在起作用。对于没有 Skills 的 LLM，只能聊天/只能建议/不能落地

| Skill | 大白话 |
| :-----| :---- | 
| 写文件 | 能真的在你项目里创建 / 修改代码 |
| 运行命令 | 能帮你 `npm test` / `docker build`等 | 
| 查数据库 | 能查数据、生成 SQL|
| 读（分析）项目| 能理解整个项目上下文 |

####    Tools 和 Skills 的区别
1、Tool，一般是点一下干一件事，如查日志、查代码、查配置

2、Skill，知道先干啥、再干啥、最后干啥。如**查日志 --> 查代码 --> 查配置 --> 给结论**

3、一个 Skill，通常等于多个 Tool 按顺序组合起来

##  0x05 MCP（Model Context Protocol）
MCP 是给大模型统一接外部能力的插线板标准，只要你按 MCP 协议提供能力，任何支持 MCP 的大模型 / Agent 都能用你（MCP）。比如开发者实现了如下能力列表（基于MCP规范），可以实现为一个Server或者封装为tools的集合，这样claude cli/cursor都可以使用

1.  查公司内部接口文档
2.  调用内部服务
3.  访问私有仓库

常用框架[mcp-go](https://github.com/mark3labs/mcp-go)，参考[]()

##  0x06 Rules
Rules 是约束大模型别乱来、别自作聪明的行为规范，由于 LLM 天性（太积极/太自信/太爱发挥），所以需要立规矩（Rules），通常要指定：

-   你是谁
-   你能干什么
-   你不能干什么
-   遇到不确定时怎么办

如在 Cursor 里优化代码，需要明确指定：能改哪些文件/不能做哪些事/是否允许引入新依赖/不确定时如何处理/只修改我点名的文件/指定代码风格/指定文档风格等等

Rules 本质上是**把隐性经验变成显性约束**，把人的经验，变成 AI 必须遵守的约束

##  0x07 Vibe-coding（感觉编程）
Vibe-coding即用户大概说个意思，你自由发挥写代码，典型对话如下。如**给我写一个网页，要看起来像80年代的科幻电影，霓虹灯风格，有个会动的飞船在背景里**

```
帮我写个登录功能
大概差不多就行
你看着办
```

结果可能是（快、错误多）

```
AI 写一大堆
能跑，但不一定对
架构未必符合你项目
```

比较适合Demo/原型验证/学习新技术/一次性脚本等简单快速场景，不适合复杂业务/长期维护/团队协作等

##  0x08 Spec-coding（规格编程）
Spec-coding，即我（用户）先写清楚规格，你（AI）严格按说明实现。一种场景是先给 AI 一个明确说明书（Spec）：

```
目标和背景
输入 / 输出
修改范围
约束条件
边界情况
代码规范
```

要求精确控制每一个细节, 然后 AI 才开始写代码。此时用户是产品 + 架构师，而AI 是一个执行力极强的高级工程师（稳定/可复用/规范/可协作等），较为适合真实业务 + 团队开发

####  Spec-coding VS Rules

-   rules：长期规则（全局）
-   spec coding：一次任务的临时规格

##  0x09 Agent（重要）
Agent（智能体）：会自己做决定、会调用工具、会把事情一步步做完的 AI 执行者，大模型的全权委托代理人。Agent 的四大核心组件：

1.  大脑 （LLM）： 负责思考、理解你的意图、拆解任务
2.  规划 （Planning）： 它是走一步看三步的。它会想为了完成目标，我第一步干啥，第二步干啥，如果出错了怎么办？
3.  记忆 （Memory）：包括短期记忆（记得刚才聊了啥）、长期记忆（记得你的偏好，比如你只坐南航的飞机，或者你写代码喜欢用 Python等）
4.  工具箱 （MCP/Tools/Skills）： 能自主决定什么时候去翻帮内部文档（MCP）、什么时候去写代码(Tools)、什么时候去查天气 （Skills）

更形象的例子：

```
你（老板）站在工厂门口，面对着 Agent（你的员工）
Agent 里面装着一个 LLM（聪明的大脑）
Agent 身上插着 MCP（万能插座），随时能通过 Skills（工具）去干活
墙上贴着 Rules（家规），Agent 干活时不敢违反
如果你今天心情好，你就跟它玩 Vibe-coding（给我整点酷的）
如果你今天要上线大项目，你就给它发一份 Spec-coding（按图纸施工，别废话）
```

##  0x0A   智能体的N种架构实现
参考[AI智能体构建总结](https://mp.weixin.qq.com/s/6kNF9jaHIyX0qhASrl6zSg)

第 1 部分：基础模式 (Notebooks 1-4)

    涵盖增强单个智能体的基本构建块：Reflection（反思）、Tool Use（工具使用）、ReAct（推理/行动循环）和 Planning（规划）。

第 2 部分：多智能体协作 (Notebooks 5, 7, 11, 13)

    探索智能体如何协同工作：Multi-Agent Systems（多智能体团队）、Meta-Controller（智能路由器）、Blackboard Systems（共享内存协作）和 Ensemble（并行多样化分析）。

第 3 部分：高级记忆与推理 (Notebooks 8, 9, 12)

    专注于智能体如何进行更深入的思考和记忆：Episodic + Semantic Memory（双重记忆系统）、Graph World-Model（图结构化知识推理）和 Tree of Thoughts（系统化多路径探索）。

第 4 部分：安全性、可靠性和真实世界交互 (Notebooks 6, 10, 14, 17)

    构建可在生产环境中信任的智能体：Dry-Run Harness（安全模拟/人工审批）、Simulator（行动前模拟）、PEV（规划、执行、验证的错误恢复）和 Metacognitive（理解自身局限性）。

第 5 部分：学习与适应 (Notebooks 15, 16)

    探索智能体如何随时间改进和以新颖方式解决问题：Self-Improvement Loop（自我改进/类RLHF学习）和 Cellular Automata（元胞自动机，简单规则产生复杂全局行为）。

智能体架构 1：反思 (Reflection)

反思模式将大型语言模型（LLM）从一个简单的、单次通过的生成器提升为一个更审慎、更可靠的推理器。它模仿了人类 “起草、审阅、编辑” 的过程，让智能体在返回最终答案之前，先退一步批评、分析和完善自己的工作。

图片

定义：反思架构涉及智能体在返回最终答案之前，批评和修订 自己的输出。它从单次生成转变为一个多步骤的内部独白：生产（Produce）、评估（Evaluate）和改进（Improve）。

高层工作流：

    生成 (Generate)： 智能体根据用户提示生成初始草稿或解决方案。
    批评 (Critique)： 智能体切换角色为批评者，进行自我提问，例如：“这个答案有什么问题？”、“是否最优？”、“有没有逻辑错误或 Bug？”
    完善 (Refine)： 利用自我批评的见解，智能体生成最终的、改进后的版本。

方面
	
描述
何时使用	代码生成：
 充当代码审阅者，修正 Bug 和提高效率。复杂总结： 确保总结全面准确，没有遗漏关键细节。内容创作： 优化语气、清晰度和影响力。
优势 (Strengths)	质量提升：
 直接解决和纠正错误，输出更准确、可靠。低开销： 概念简单，只需单个 LLM 即可实现，无需复杂的外部工具。
劣势 (Weaknesses)	自我局限：
 智能体仍受限于自身知识和偏见，无法凭空创造它所缺乏的知识。延迟与成本增加： 至少涉及两次 LLM 调用（生成 + 批评/完善），比单次通过更慢、更昂贵。
智能体架构 2：工具使用 (Tool Use)

工具使用架构是连接大型语言模型（LLM）推理能力与真实、动态世界的 桥梁。它赋予智能体查询 API、搜索数据库和访问实时信息的能力，从而克服了 LLM 知识的静态局限性。

图片

定义：工具使用 架构为 LLM 驱动的智能体配备了调用外部函数或 API（即 “工具”）的能力。智能体能够自主判断用户查询是否需要外部信息，并决定调用哪个工具来获取所需数据。

高层工作流：

    接收查询 (Receive Query)： 智能体接收用户的请求。
    决策 (Decision)： 智能体分析查询和可用工具，判断是否需要工具。
    行动 (Action)： 如果需要，智能体格式化对工具的调用（例如，带正确参数的特定函数）。
    观察 (Observation)： 系统执行工具调用，并将结果（“观察结果”）返回给智能体。
    合成 (Synthesis)： 智能体将工具的输出整合到其推理过程中，生成一个最终的、有事实依据 的答案。

方面
	
描述
何时使用	研究助理：
 使用网络搜索 API 回答需要最新信息的查询。企业助理： 查询内部数据库以获取实时业务数据。科学计算： 使用计算引擎进行 LLM 难以精确处理的数学和科学计算。
优势 (Strengths)	事实依据 (Factual Grounding)：
 通过获取实时数据，显著减少 幻觉 (Hallucinations)。可扩展性 (Extensibility)： 智能体的能力可以简单地通过添加新工具持续扩展。
劣势 (Weaknesses)	集成开销 (Integration Overhead)：
 需要仔细定义工具、管理 API 密钥和处理潜在的工具调用失败。工具信任 (Tool Trust)： 最终答案的质量取决于所使用工具的可靠性和准确性。
智能体架构 3：ReAct (Reason + Act)

ReAct (Reason + Act，即“推理 + 行动”) 是一种关键的智能体架构，它弥合了简单的工具使用和复杂的、多步骤问题解决之间的差距。它的核心创新在于允许智能体 动态地交错推理和行动，从而成为一个自适应的问题解决者。

定义：ReAct 架构是一种设计模式，智能体在其中 交替进行推理步骤和行动。智能体不是预先规划所有步骤，而是生成关于其下一步行动的内部思考，然后执行一个行动（如调用工具），观察 结果，并利用新信息生成下一个思考和行动。这创建了一个动态和自适应的循环。

高层工作流：

    接收目标 (Receive Goal)： 智能体接收一项复杂的任务。
    思考 (Think / Reason)： 智能体生成一个内部思考，例如：“为了回答这个问题，我首先需要找到信息 X。”
    行动 (Act)： 根据思考，智能体执行一个行动，通常是调用工具（例如：search_api('X')）。
    观察 (Observe)： 智能体接收到工具返回的结果。
    重复 (Repeat)： 智能体将观察结果纳入其上下文，返回第 2 步，生成一个新的思考（例如：“好的，既然我有了 X，我现在需要用它来找到 Y。”）。这个循环持续进行，直到总体目标达成。





方面
	
描述
何时使用	多跳问答 (Multi-hop Q&A)：
 回答需要按顺序查找多个信息的查询（例如：“制造 iPhone 的公司现任 CEO 是谁？”）。网络导航与研究： 智能体根据上一步的搜索结果动态调整下一搜索词。交互式工作流： 任何无法预先知道完整解决路径、环境动态变化的复杂任务。
优势 (Strengths)	自适应和动态：
 可以根据新信息即时调整其计划。处理复杂性： 擅长需要链接多个依赖步骤的问题。
劣势 (Weaknesses)	更高的延迟与成本：
 涉及多个顺序的 LLM 调用，比单次通过方法更慢、更昂贵。循环风险： 引导不当的智能体可能会陷入重复、低效的思考和行动循环中。
智能体架构 4：规划 (Planning)

规划 (Planning) 架构在智能体的推理过程中引入了至关重要的 **预见性 (foresight)**。与 ReAct 模式（步步为营、即时反应）不同，规划智能体在采取任何行动 之前，会先将一个复杂的任务分解成一系列更小、可管理的子目标，制定一个完整的“作战计划”。

图片

定义：规划 架构涉及智能体在开始执行 之前，将复杂的总目标明确分解为一个详细的、按顺序排列的子任务列表。初始规划阶段的输出是一个具体的、循序渐进的计划，智能体随后将有条不紊地遵循该计划来解决问题。

高层工作流：

    接收目标 (Receive Goal)： 智能体接收一个复杂任务。
    规划 (Plan)： 专门的 “规划器 (Planner)” 组件分析目标，并生成一个有序的子任务列表，例如：["查找事实 A", "查找事实 B", "使用 A 和 B 计算 C"]。
    执行 (Execute)： 一个 “执行器 (Executor)” 组件按照计划，顺序执行每个子任务，并根据需要使用工具。
    合成 (Synthesize)： 一旦计划中的所有步骤都完成，一个最终组件会整合执行步骤的结果，生成一个连贯的最终答案。



方面
	
描述
何时使用	多步骤工作流：
 适用于操作顺序已知且关键的任务，如生成报告（获取数据 
 处理 
 总结）。项目管理： 将“发布新功能”等大型目标分解为各团队的子任务。教学辅导： 制定教学计划，从基础到应用教授特定概念。
优势 (Strengths)	结构化和可追溯：
 整个工作流程预先设定，过程透明，易于调试。高效： 对于可预测的任务，可以避免 ReAct 在每一步之间进行额外的推理循环，从而提高效率。
劣势 (Weaknesses)	对变化脆弱 (Brittle to Change)：
 如果环境在执行过程中发生意外变化，预先制定的计划可能会失败。它不如 ReAct 智能体那样具有自适应性。
智能体架构 5：多智能体系统 (Multi-Agent Systems)

多智能体系统 (Multi-Agent System, MAS) 是最强大和灵活的架构之一。它超越了单个智能体的概念，转而模拟一个由 专业化智能体 组成的团队，通过 协作 来解决问题。每个智能体都有独特的角色、个性和技能集，模仿了人类专家团队的工作方式。

定义：多智能体系统 是一种架构，其中一组截然不同、高度专业的智能体通过协作（有时是竞争）来实现一个共同目标。系统使用一个中央控制器或定义的工作流协议来管理智能体之间的通信和任务路由。

高层工作流：

    分解 (Decomposition)： 主控制器或用户提供一个复杂的任务。
    角色定义 (Role Definition)： 系统根据智能体的定义角色（例如：‘研究员’、‘编码员’、‘评论家’、‘作家’）将子任务分配给专业的智能体。
    协作 (Collaboration)： 智能体执行各自的任务，通常是并行或顺序进行。它们将输出传递给彼此或一个中心“黑板”。
    合成 (Synthesis)： 最后一个“管理员”或“合成器”智能体收集所有专业智能体的输出，并组装成最终的、整合后的响应。





方面
	
描述
何时使用	复杂报告生成：
 创建需要多个领域专业知识的详细报告（例如：财务分析、市场研究）。软件开发流水线： 模拟一个包含程序员、代码审查员和项目经理的开发团队。创意头脑风暴： 由具有不同“个性”的智能体（乐观、谨慎、富有创意）组成的团队，可以产生更多样化的想法。
优势 (Strengths)	专业化和深度：
 每个智能体都可以针对特定领域进行微调，从而在其领域内产出更高质量的工作。模块化和可扩展性： 可以轻松添加、移除或升级单个智能体，而无需重新设计整个系统。并行性： 多个智能体可以同时处理其子任务，可能缩短总体任务时间。
劣势 (Weaknesses)	协调开销：
 管理智能体之间的通信和工作流程，增加了系统设计的复杂性。成本和延迟增加： 运行多个智能体涉及更多的 LLM 调用，可能比单一智能体方法更昂贵、更慢。
智能体架构 6：规划器 
 执行器 
 验证器 (PEV)

规划器 
 执行器  验证器 (Planner  Executor 

 Verifier, PEV) 架构引入了智能体系统中至关重要的 鲁棒性 (robustness) 和 自我修正 (self-correction) 层。它借鉴了严格的软件工程和质量保证流程，即工作只有在经过验证后才算“完成”。

定义：Planner 
 Executor 

 Verifier (PEV) 架构是一种三阶段工作流，它明确分离了 规划、执行和验证 的行为。它确保在智能体继续下一步之前，对每一步的输出进行验证，从而创建了一个鲁棒的、自我修正的循环。

高层工作流：

    规划 (Plan)：‘规划器’ 智能体将高层目标分解成一系列具体的、可执行的步骤。
    执行 (Execute)：‘执行器’ 智能体执行计划中的 下一个 步骤并调用相应的工具。
    验证 (Verify)：‘验证器’ 智能体检查执行器的输出。它检查正确性、相关性和潜在错误，然后给出判断：该步骤是成功还是失败？
    路由与迭代 (Route & Iterate)： 根据验证器的判断，路由器决定下一步行动：
        如果步骤 成功 且计划未完成，返回执行器执行下一步。
        如果步骤 失败，返回 规划器 创建一个 新的计划，通常会提供失败的上下文，使新计划更智能。
        如果步骤 成功 且计划完成，进入最终合成步骤。





方面
	
描述
何时使用	安全关键应用：
 （金融、医疗）错误成本很高时，PEV 提供必要的保障措施，防止智能体基于错误数据行动。工具不可靠的系统： 处理可能不稳定或返回不一致数据的外部 API 时，验证器可以优雅地捕获故障。高精度任务： （法律、科学）对事实准确性要求高时，验证器确保检索到的每一条信息在使用前都是有效的。
优势 (Strengths)	鲁棒性与可靠性：
 核心优势是检测和从错误中恢复的能力。模块化： 职责分离使系统更易于调试和维护。
劣势 (Weaknesses)	更高的延迟与成本：
 在每次行动后增加验证步骤，涉及更多的 LLM 调用，使其成为目前最慢、最昂贵的架构。验证器复杂性： 设计一个有效的验证器具有挑战性，它需要足够智能，能够区分小问题和关键故障。
智能体架构 7：黑板系统 (Blackboard Systems)

黑板系统 (Blackboard System) 是一种强大且高度灵活的多智能体协作模式。它借鉴了人类专家团队围绕一块实体黑板共同解决复杂问题的理念。

与僵硬、预定义的智能体传递序列不同，黑板系统具有一个中央的、共享数据存储库（即“黑板”）。智能体可以在黑板上读取问题的当前状态，并写下它们的贡献。一个 动态控制器 持续观察黑板，并根据解决问题所需的内容，决定下一步激活哪个专业智能体。这实现了一种 机会主义 (opportunistic) 和 自发涌现 (emergent) 的工作流程。

定义：黑板系统 是一种多智能体架构，其中多个专业智能体通过读取和写入一个名为 “黑板” 的共享中央数据存储库进行协作。一个 控制器或调度器 根据黑板上不断演变的解决方案状态，动态地决定下一个应该采取行动的智能体。

高层工作流：

    共享内存（黑板）： 中央数据结构保存问题的当前状态，包括用户请求、中间发现和部分解决方案。
    专业智能体： 一组独立的智能体（拥有特定专业知识）持续监控黑板。
    控制器 (Controller)： 一个中央“控制器”智能体监控黑板，分析当前状态，并决定哪个专业智能体最适合做出下一个贡献。
    机会主义激活： 控制器激活选定的智能体。该智能体从黑板上读取相关数据，执行任务，并将发现结果写回黑板。
    迭代： 过程重复，控制器以动态序列激活不同的智能体，直到确定黑板上的解决方案已完成。

方面
	
描述
何时使用	复杂的、结构不良的问题：
 解决方案路径事先未知，需要一种自发涌现、机会主义策略的问题（例如：复杂诊断、科学发现）。多模态系统： 协调处理不同数据类型（文本、图像、代码）智能体的绝佳方式。动态态势感知： 需要从许多分散、异步的来源合成信息的场景。
优势 (Strengths)	灵活性和适应性：
 工作流程不是硬编码的，而是根据问题自发产生的，系统具有高度适应性。模块化： 增删专业智能体非常容易，无需重新架构整个系统。
劣势 (Weaknesses)	控制器复杂性：
 整个系统的智能程度严重依赖于控制器的复杂性。一个简单的控制器可能导致低效或循环行为。调试挑战： 工作流程的非线性、自发涌现特性有时使追踪和调试比简单的顺序过程更困难。
智能体架构 8：情景记忆 + 语义记忆堆栈

标准的聊天机器人记忆是短暂的，只持续一个会话。为了构建一个能够随着用户学习和成长的个性化智能体，我们需要一种更强大的解决方案。该架构通过结合两种不同的记忆类型，模拟了人类的认知，实现了结构化的记忆体系：
记忆类型
	
定义
	
存储方式
	
作用
情景记忆 (Episodic Memory)	
记录特定事件或过去交互的记忆。回答 “发生了什么？”（例如：“上周，用户问我关于英伟达股价的问题。”）
	向量数据库	
用于基于语义相似性检索相关的历史对话。
语义记忆 (Semantic Memory)	
从这些事件中提取的结构化事实、概念和关系。回答 “我知道什么？”（例如：“用户 Alex 是保守型投资者。”）
	图数据库 (Neo4j)	
擅长管理和查询实体间的复杂关系。

通过结合这两种记忆，智能体不仅能回忆起过去的对话，还能建立一个丰富、相互关联的知识库，从而实现深度个性化和上下文感知的交互。

该架构引入了一个完整的循环，涵盖了记忆的检索（Recall）和创建（Encoding）：

    交互 (Interaction)： 用户发起查询。
    记忆检索（回忆）： 智能体查询两个记忆系统：
        情景记忆： 搜索向量存储，查找相似的过往对话。
        语义记忆： 查询图数据库，查找与查询相关的实体和事实。
    增强生成 (Augmented Generation)： 检索到的记忆被添加到 LLM 的提示上下文，使模型能够生成一个了解过去交互和已习得事实的个性化响应。
    记忆创建（编码）： 交互完成后，后台进程分析对话：
        创建一个简洁的轮次摘要（新的情景记忆）。
        提取关键实体和关系（新的语义记忆）。
    记忆存储： 新的情景摘要被嵌入并保存到向量存储中。新的语义事实以节点和边的形式写入图数据库。

方面
	
描述
何时使用	长期个人助理：
 助理能记住用户数周或数月内的偏好、项目和个人细节。个性化系统： 记住用户风格的电商机器人，或记住学习进度和弱点的教育辅导员。复杂研究智能体： 在探索文档时构建主题知识图谱的智能体，使其能够回答复杂的、多跳的问题。
优势 (Strengths)	真正的个性化：
 实现了超越单个会话上下文窗口的持久化学习和上下文。丰富的理解： 图数据库允许智能体理解和推理实体间的复杂关系。
劣势 (Weaknesses)	复杂性：
 这是一个比简单无状态智能体复杂得多的架构，难以构建和维护。记忆膨胀与修剪： 随着时间推移，记忆存储可能变得巨大。必须制定策略来摘要、合并或修剪旧的/不相关的记忆。
智能体架构 9：思维树规划 (Tree-of-Thoughts, ToT)

ToT 智能体不是生成单一的、顺序的推理线，而是在问题的每个阶段生成多个候选的 “思维” 或下一步。然后，它评估这些思维，修剪 (pruning) 无效或前景不佳的分支，并 扩展 (expanding) 最有希望的分支。这创建了一个搜索树，智能体可以在其中回溯、探索替代方案，并系统地导航复杂的问题空间。

图片

定义：思维树 (Tree-of-Thoughts, ToT) 是一种智能体推理框架，其中问题解决被建模为在树中进行的搜索。智能体同时探索多个推理路径（分支）。在每一步，它生成潜在的下一步（“思维”），评估其可行性，并决定继续探索哪些路径，从而有效地修剪搜索空间。

高层工作流：

    分解 (Decomposition)： 问题被分解成一系列步骤或思维。
    思维生成 (Thought Generation)： 对于问题的当前状态，智能体生成多个潜在的下一步或思维。这在搜索树中创建了分支。
    状态评估 (State Evaluation)： 每一个新思维（导致新状态）都会被一个“批评者”或验证函数评估，评估其：
        有效性 (Validity)： 该行动是否符合问题规则？
        进度 (Progress)： 该行动是否让我们更接近解决方案？
    修剪与扩展 (Pruning & Expansion)： 无效或前景不佳的分支被修剪。智能体随后从最有希望的活跃分支继续，重复思维生成过程。
    解决方案 (Solution)： 过程持续到达到目标状态。解决方案就是从根节点到目标状态的思维路径。

方面
	
描述
何时使用	逻辑谜题与数学问题：
 具有明确规则和目标状态，需要多步骤、非线性推理的问题（例如：数独、过河谜题）。复杂规划： 任务需要详细规划，操作顺序至关重要且必须遵守约束（例如：规划复杂的多站旅行）。创意写作或代码生成： 在决定采用哪个故事分支或实施策略之前，探索多种可能性。
优势 (Strengths)	鲁棒性 (Robustness)：
 系统地探索问题空间，与单次推理方法相比，不太可能陷入困境或产生错误答案。处理组合复杂性： 非常适用于可能序列数量庞大的问题。
劣势 (Weaknesses)	计算成本高：
 需要比简单的思维链提示多得多的 LLM 调用和状态管理，使其更慢、更昂贵。依赖良好的评估器： 搜索的有效性严重依赖于状态评估逻辑的质量。

智能体被构建为一个 LangGraph 图，其核心逻辑是一个循环：

    初始化： 设置初始状态。
    扩展 (Expand)： 遍历当前所有活跃路径，使用 get_possible_moves 函数生成所有有效的下一步（思维），创建新的分支。
    修剪 (Prune)： 检查新路径：
        有效性检查： 尽管生成函数已保证有效，但在此处可进行额外检查。
        循环检查： 如果路径的最后一个状态在之前出现过（形成循环），则修剪该路径。
    检查解决方案： 如果任何活跃路径达到目标状态，则停止。否则，回到 扩展 步骤。

智能体架构 10：模拟器 / 心智模型在环 (Simulator-in-the-Loop)

核心思想是让智能体以非常具体的方式 “三思而后行”。智能体不会立即在现实世界中执行提议的行动，而是首先在环境的内部模拟版本中测试该行动。通过观察这个安全沙盒中可能产生的后果，智能体可以评估风险、完善策略，然后才在现实中执行一个更经过深思熟虑的行动。

图片

定义：模拟器 或 心智模型在环 架构涉及一个智能体，它利用其环境的内部模型来 模拟 潜在行动的结果，然后再执行这些行动。这使智能体能够进行 **假设分析 (what-if analysis)**、预测后果，并优化其计划以确保安全性和有效性。

高层工作流：

    观察 (Observe)： 智能体观察现实环境的当前状态。
    提议行动 (Propose Action)： 智能体的规划模块根据目标和当前状态，生成一个高层次的拟议行动或策略。
    模拟 (Simulate)： 智能体将环境的当前状态 分叉 (forks) 到一个沙盒模拟中。它应用拟议的行动，并向前运行模拟以观察一系列可能的结果。
    评估与完善 (Assess & Refine)： 智能体分析模拟结果。该行动是否导致了期望的结果？是否存在不可预见的负面后果？基于此评估，它将最初的提案完善为一个最终、具体的行动。
    执行 (Execute)： 智能体在 真实 环境中执行最终、完善后的行动。
    重复 (Repeat)： 循环从现实环境的新状态开始。

方面
	
描述
何时使用	机器人技术：
 在移动物理手臂之前模拟抓取或路径，以避免碰撞或损坏。高风险决策： 在金融领域，模拟交易在不同市场条件下的投资组合影响；在医疗保健领域，模拟治疗计划的潜在效果。复杂游戏 AI： 策略游戏中的 AI 模拟几步前的行动来选择最优解。
优势 (Strengths)	安全与风险降低：
 通过首先在安全环境中审查行动，极大地减少了有害或代价高昂错误的发生几率。性能提升： 允许前瞻和规划，从而做出更健壮、更周到的决策。
劣势 (Weaknesses)	模拟-现实差距 (Simulation-Reality Gap)：
 有效性完全取决于模拟器的逼真度。如果世界模型不准确，智能体的计划可能基于错误的假设。计算成本： 运行模拟（尤其是多个场景）的计算成本很高，并且比直接行动要慢。
智能体架构 12：图 / 世界模型记忆 (Graph / World-Model Memory)

基于图的智能体不将信息存储为孤立的文本块，而是将传入数据解析为实体（节点）和关系（边），从而创建一个丰富、可查询的知识图谱。智能体随后可以通过遍历该图谱来回答复杂问题，发现隐藏在非结构化文本中的洞察。

图片

定义：图 / 世界模型记忆 是一种智能体架构，其中知识存储在结构化的图数据库中。信息被表示为节点（实体，如人、地点、概念）和边（它们之间的关系）。这创建了一个动态的“世界模型”，智能体可以基于此进行推理。

高层工作流：

    信息摄取 (Information Ingestion)： 智能体接收非结构化或半结构化数据（文本、文档等）。
    知识提取 (Knowledge Extraction)： 一个由 LLM 驱动的流程解析信息，识别关键实体及其相互连接的关系。
    图谱更新 (Graph Update)： 提取的节点和边被添加或更新到持久化的图数据库中（如 Neo4j）。
    问答 / 推理 (Question Answering / Reasoning)： 当被问及问题时，智能体执行以下步骤： a. 将自然语言问题转换为正式的图查询语言（例如：Neo4j 的 Cypher）。 b. 对图谱执行查询以检索相关的子图或事实。 c. 将查询结果合成为自然语言答案。

方面
	
描述
何时使用	企业知识助手：
 从内部文档中构建公司项目、员工和客户的可查询模型。高级研究助手： 通过摄取研究论文创建科学领域的动态知识库。复杂系统诊断： 对系统组件及其依赖关系进行建模以诊断故障。
优势 (Strengths)	结构化与可解释：
 知识高度组织化。可以通过显示图谱中导致答案的确切路径来解释答案。实现复杂推理： 擅长回答需要通过关系连接分散信息，即“多跳”问题。
劣势 (Weaknesses)	前期复杂性：
 需要定义良好的模式和一个鲁棒的提取过程。图谱更新管理： 难以管理更新、解决冲突信息以及随时间修剪过时事实（知识生命周期管理）。

使用具有结构化输出（Pydantic）的 LLM 作为知识提取器。它读取文本，并以 Node 和 Relationship 的形式提取实体和关系（关系类型被大写，如 ACQUIRED）。

智能体处理了三份相互关联但独立的文件，逐步构建知识图谱：

    文档 1： AlphaCorp ACQUIRED BetaSolutions。
    文档 2： Dr. Evelyn Reed WORKS_FOR AlphaCorp，AlphaCorp PRODUCES QuantumLeap AI。
    文档 3： Innovate Inc. 的 NeuraGen COMPETES_WITH QuantumLeap AI。 该智能体实现了 文本到 Cypher 的完整管道：

    生成 Cypher 查询： LLM 将自然语言问题转换为 Cypher 语句。
    执行查询： 在 Neo4j 图数据库上运行 Cypher 语句以获取上下文。
    合成最终答案： LLM 基于查询结果提供自然语言答案。

智能体架构 13：并行探索 + 集成决策 (Parallel Exploration + Ensemble Decision)

通过对 AI 智能体应用“群体的智慧”原则，解决了单个 LLM 固有的不确定性和潜在偏差问题。不依赖于单一的推理线，而是同时衍生出多个独立的智能体，从不同的视角分析问题。每个智能体遵循自己的推理路径，如同专家委员会中的不同专家。然后，一个最终的“聚合器”智能体收集并合成它们的个人结论，权衡不同的观点，找出共识和冲突，从而产生一个更细致、更可靠的最终答案。


定义：并行探索 + 集成决策 是一种智能体架构，其中一个问题由多个独立的智能体或推理路径同时处理。然后，通过一个单独的智能体（通常是聚合器），采用投票、建立共识或合成等方法，将所有单独的输出进行集成，从而得出最终、更健壮的结论。

高层工作流：

    扇出（并行探索）： 用户查询被分发给 N 个独立的专业智能体。这些智能体通常被赋予不同的指令、角色或工具，以鼓励分析方法的多样性。
    独立处理： 每个智能体单独处理问题，生成自己的完整分析、结论或答案。
    扇入（聚合）： 收集所有 N 个智能体的输出。
    合成（集成决策）： 最终的“聚合器”或“裁决者”智能体接收所有单个输出。它的任务是分析这些观点，找出共同点，权衡冲突的证据，并合成一个全面而平衡的最终答案。

方面
	
描述
何时使用	困难推理问答：
 对于单一推理线容易遗漏细节的复杂、模糊问题。事实核查与验证： 让多个智能体从不同来源搜索和验证事实，可以大幅减少幻觉（虚构信息）。高风险决策支持： 在医学或金融等领域，在做出推荐前，从不同的 AI 角色那里获得“第二意见”（或第三、第四意见）。
优势 (Strengths)	提升可靠性和准确性：
 平均化单个智能体的随机错误或偏见，使最终答案更有可能正确且全面。减少幻觉： 如果一个智能体虚构了事实，其他智能体不太可能这样做，聚合器很容易发现异常值。
劣势 (Weaknesses)	成本极高：
 这是计算成本最高的架构之一，因为它将 LLM 调用的数量乘以集成中的智能体数量（再加上最终的聚合调用）。延迟增加： 在最终合成开始之前，系统必须等待所有并行路径完成。
智能体架构 14：可观测性 + 演习线束 (Dry-Run Harness)

在没有确切知道智能体将要做什么之前，绝不在实时环境中运行其行动。 此架构将“三思而后行 (look before you leap)”的过程正式化。智能体首先在 演习模式（dry_run） 下执行其计划，该模式不会改变真实世界，但会生成详细的日志和清晰的行动计划。然后，此计划会被提交给人类（或自动检查器）批准，之后才允许最终的实时执行。

定义：可观测性与演习线束 是一种测试和部署架构，它会拦截智能体的行动。它首先在“演习”或“沙盒”模式下执行这些行动，模拟 行动而不会造成真实世界的影响。由此产生的计划和日志会被呈现供审阅，只有在明确批准后，行动才会在实时环境中执行。

高层工作流：

    智能体提出行动 (Agent Proposes Action)： 智能体确定一个计划或特定的工具调用。
    演习执行 (Dry Run Execution)： 线束使用 dry_run=True 标志调用智能体的计划。底层工具被设计为识别此标志，并只输出它们将要做什么，以及相应的日志和追踪。
    收集可观测性数据 (Collect Observability Data)： 线束捕获拟议的行动、演习日志和任何相关的追踪数据。
    人类/自动化审阅 (Human/Automated Review)： 这些可观测性数据被呈现给审阅者。人类可以检查正确性、安全性和目标一致性。自动化系统可以运行策略违规检查。
    批准/否决决策 (Go/No-Go Decision)： 审阅者做出“批准”或“拒绝”的决定。
    实时执行（在“批准”时）： 如果获得批准，线束会重新执行智能体的行动，但这次是 dry_run=False，从而使其产生真实世界的影响。

方面
	
描述
何时使用	生产验证与安全：
 任何可以修改状态、花费金钱、发送通信或执行任何其他不可逆行动的智能体的永久生产功能。调试和测试： 在开发中，了解智能体如何解释任务以及它正在采取什么行动而没有副作用。智能体的 CI/CD： 将演习线束集成到自动化测试管道中，以在部署新版本之前验证智能体的行为。
优势 (Strengths)	最大透明度和安全性：
 提供智能体行动的清晰、可审计的预览，防止代价高昂或令人尴尬的错误。非常适合调试： 轻松追踪智能体的逻辑和工具调用，而无需撤销真实世界的更改。
劣势 (Weaknesses)	延迟部署/执行：
 强制性的审阅步骤（尤其是涉及人类时）会引入延迟，使其不适合实时应用程序。要求工具支持： 智能体使用的工具和 API 必须设计为支持 dry_run 模式。
智能体架构 15：自我改进循环 (Self-Improvement Loop)

**自我改进循环 (Self-Improvement Loop)迭代地完善其输出，从而达到更高的质量标准。它是让智能体随着时间从良好的基线水平提升到专家级表现的机制。

这个过程模仿了人类“做 
 获得反馈 

 改进”的学习周期。Notebook 通过一个 自优化 (Self-Refine) 工作流来实现这一点：智能体的输出立即由一个批评子智能体进行评估，如果发现不足，则要求原始智能体根据可操作的反馈修改其工作。

定义：自我改进循环 是一种智能体架构，其中智能体的输出由其自身或另一个智能体进行评估，并将此评估用作反馈，以生成一个经过修订的、更高质量的输出。当这种反馈被存储并用于随着时间推移改善智能体的基线性能时，它就成为一种持续学习的形式。

高层工作流（自优化）：

    生成初始输出 (Generate Initial Output)： 主要智能体生成解决方案的第一个版本（“草稿”）。
    批评输出 (Critique Output)： 批评智能体（或处于“批评模式”下的主要智能体）根据一组预定义的标准或一般准则评估草稿。
    决策 (Decision)： 系统检查批评是否足够积极以接受输出。
    修订（循环）(Revise / Loop)： 如果输出不被接受，原始草稿和批评者的反馈将传递回主要智能体，指示其生成一个解决反馈的修订版本。
    接受 (Accept)： 一旦输出达到质量标准，循环终止，返回最终版本。

方面
	
描述
何时使用	高质量内容生成：
 对通用初稿不足以胜任的任务，例如撰写法律文件、详细技术报告或有说服力的营销文案。持续学习与个性化： 通过生成响应、获得隐性或显性反馈，并完善其内部策略，从而学习用户偏好的智能体。复杂问题解决： 智能体可以提出一个计划，批评其缺陷或效率低下之处，然后在执行前修订计划。
优势 (Strengths)	显著提高输出质量：
 迭代优化始终比单次生成产生更好的结果。实现持续学习： 为智能体提供一个随着时间推移，根据新信息或反馈不断改进的框架。
劣势 (Weaknesses)	强化偏差的风险：
 如果批评智能体具有有缺陷的逻辑或偏差，系统可能会陷入一个强化自身错误的循环。计算成本高昂： 迭代性质意味着每个任务需要多次 LLM 调用，增加了成本和延迟。
智能体架构 16：元胞自动机 / 网格系统

在这个模型中，环境本身就变成了智能体。网格中的每个单元格都是一个微型智能体，拥有自己的状态和一套简单的规则，用于根据其紧邻的邻居来更新状态。没有中央控制器或复杂的寻路算法。相反，智能的、全局的行为是简单局部规则重复、同步应用后涌现 (emerges) 出来的。系统变成了一个“计算结构”，通过信息的波状传播来解决问题。

定义：基于网格的智能体系统 是一种架构，其中大量简单的智能体（或“单元格”）排列在一个空间网格中。每个智能体都有一个状态，并根据仅考虑其紧邻邻居状态的规则集同步更新其状态。复杂、高层次的模式和问题解决能力从这些局部交互中涌现出来。

高层工作流：

    网格初始化 (Grid Initialization)： 创建单元格智能体网格，每个单元格初始化一个类型（如：障碍物、空白）和一个状态（如：一个值）。
    设置边界条件 (Set Boundary Conditions)： 一个或多个单元格被赋予特殊状态以启动计算（例如，将“目标”单元格的值设置为 0）。
    同步时钟 (Synchronous Tick)： 系统“滴答”向前。在每个时钟周期，每个单元格根据其邻居的当前状态同时计算其下一个状态。
    涌现 (Emergence)： 随着系统的推进，信息像波浪一样在网格中传播。这会创建梯度、路径和其他复杂结构。
    状态稳定 (State Stabilization)： 系统运行直到网格状态稳定（不再发生变化），表明计算已完成。
    读取结果 (Readout)： 问题的解决方案直接从网格的最终状态中读取（例如，通过沿着计算出的梯度追踪）。

方面
	
描述
何时使用	空间推理与物流：
 动态环境中（如仓库示例）的最佳寻路。复杂系统模拟： 建模具有涌现行为的现象，如森林火灾、疾病传播或城市增长。并行计算： 某些算法可以映射到元胞自动机模型，以便在高度并行的硬件（如 GPU）上执行。
优势 (Strengths)	高并行性：
 逻辑本质上是并行的，在合适的硬件上速度极快。适应性： 系统可以动态地对环境变化（如新的障碍物）做出反应，只需重新传播波浪。涌现的复杂性： 可以用令人惊讶的简单规则解决非常复杂的问题。
劣势 (Weaknesses)	设计复杂性：
 设计局部规则以产生所需的全局行为可能具有挑战性且不直观。内省性差： 很难询问单个单元格为什么具有某种状态；推理分布在整个系统中。
智能体架构 17：反思性元认知智能体

元认知智能体超越了简单的自我反思。它维护着一个明确的“自我模型 (Self-Model)”——对其自身知识、工具和边界的结构化表示。当面对一项任务时，它的第一步不是解决问题，而是根据其自我模型来分析问题。它会问内部问题，例如：

    “我是否有足够的知识自信地回答这个问题？”
    “这个主题是否在我指定的专业领域内？”
    “用户查询是否涉及错误可能带来危险的高风险主题？”

根据这些答案，它会选择一种策略：直接推理、使用专业工具，或者——最重要的是——当任务超出其已知限制时上报给人类。

定义：反思性元认知智能体 是一种智能体，它维护并使用关于其自身能力、知识边界和信心水平的明确模型，来为给定任务选择最合适的策略。这种自我建模使其行为更安全、更可靠，尤其是在错误信息可能有害的领域。

高层工作流：

    感知任务 (Perceive Task)： 智能体接收用户请求。
    元认知分析（自我反思）(Metacognitive Analysis)： 智能体的核心推理引擎根据其自我模型分析请求。它评估其信心、工具的相关性，以及查询是否在其预定义的操作领域内。
    策略选择 (Strategy Selection)： 基于分析，智能体选择以下策略之一：
        直接推理 (Reason Directly)： 适用于高信心、低风险的知识库内查询。
        使用工具 (Use Tool)： 当查询需要智能体通过工具拥有的特定能力时。
        上报/拒绝 (Escalate/Refuse)： 适用于低信心、高风险或超出范围的查询。
    执行策略 (Execute Strategy)： 执行所选择的路径。
    响应 (Respond)： 智能体提供结果，可能是直接答案、工具增强的答案，或带有咨询专家指示的安全拒绝。

方面
	
描述
何时使用	高风险咨询系统：
 任何在医疗保健、法律或金融等领域提供信息的系统，智能体必须能够说“我不知道”或“您应该咨询专业人士”。自主系统： 机器人必须在尝试物理任务之前，评估自己安全执行任务的能力。复杂工具协调器： 智能体必须从庞大的库中选择正确的 API，并了解某些 API 比其他 API 更危险或成本更高。
优势 (Strengths)	增强安全性和可靠性：
 智能体被明确设计为避免在其非专业领域做出自信的断言。改进决策制定： 通过强制进行深思熟虑的策略选择，而不是天真地直接尝试，从而实现更稳健的行为。
劣势 (Weaknesses)	自我模型的复杂性：
 定义和维护准确的自我模型可能很复杂。元认知开销： 初始分析步骤增加了每个请求的延迟和计算成本。

##  0x0 RAG

##  0x0 Relations


| :-----| :---- | 
| LLM | 会接话、会写代码的超级大脑 |
| Skills | 让 AI 真正能干活的工具能力 | 
| Tools | 干活使用的一个最小工具|
| MCP| 给 AI 接外部能力的统一协议 |
| Rules |约束 AI 行为的长期规矩|
|   Vibe-coding    |靠感觉让 AI 自由发挥|
|   Spec-coding    |用规格驱动 AI 精确执行|
|   Agent    |LLM + 规划 + 记忆 + Rules+MCP+Skills|

##  0x0 参考
-   [一篇搞懂AI通识:大白话拆解核心点](https://www.cnblogs.com/Jcloud/p/19492752)
-   [AI智能体构建总结：17种架构详细实现](https://mp.weixin.qq.com/s/6kNF9jaHIyX0qhASrl6zSg)
-   [Implementation of 17+ agentic architectures designed for practical use across different stages of AI system development](https://github.com/FareedKhan-dev/all-agentic-architectures)